env agent x
TestEnv x
TestAgent x
Trainer x
alternativ miljö setting upordown x
tester olika miljöer  x
städa upordown z
dokumentera i md upordown - tex renskriv bevis derGradLog x

two armed bandit working x
clean up x
accumSum med streams  x
gradLog med mer generell matte  x
TrainingTracker  x
runner som plottar phiTheta x
TrainingTrackerPlotter  x
plantuml bandit x

short corridor x
EnvironmentSC  x
TestEnvironmentSC  x
AgentSC x
korrekt stateObserved  x
TestAgentSC x
clean up  x
tracker.addActionProbabilities x
RunnerShortCorridor  x
shortCorridor.md  x

sink the ship  x
EnvironmentShip x
TestEnvironmentShip  x

TrainerAbstractSC, record TrainerSettings med nofEpisodes etc  x

short corridor baseline TrainerWithBaselineSC  x
shortCorridor.md om baseline  x
RunnerTrainerWithBaselineSC  x
short corridor one step actor critic  TrainerWithActorCriticSC  x
Experience.copyWithReturn()  x
ny klass TabularValueFunction, för tex TrainerActorCriticSC  x
uppdatera plantuml  x


AgentShip  x
TestAgentShip  x
calcGradLogVector  createGradLogAllStates x
givenState0_whenGradLogForActionMeanS1_thenCorrect x
TrainerShip x
RunnerTrainerActorCriticShip  x
korrekt gradlog x
sinkShip.md  x
undivka div noll gradMean x
clip gragLog vektor x
sqr2 etc till MyFunctions x
tracker.addActionProbabilities  -> addMeasures etc  x
getExperiences: while(!sr.isTerminal() && si < parameters.nofStepsMax()) i andra miljör  x
TrainerAbstract  x
NormDistributionSampler x
ExperienceContAction Experience, båda!! går göra snyggare?
kommentera klasser
clean up




förstå https://www.janisklaise.com/post/rl-policy-gradients/
koda ovan

enkla dl4j exempel
ovan med anpassad loss

tex short corridor med neuronnät


bubblare:
gradLog with finite diff