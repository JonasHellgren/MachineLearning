env agent x
TestEnv x
TestAgent x
Trainer x
alternativ miljö setting upordown x
tester olika miljöer  x
städa upordown z
dokumentera i md upordown - tex renskriv bevis derGradLog x

two armed bandit working x
clean up x
accumSum med streams  x
gradLog med mer generell matte  x
TrainingTracker  x
runner som plottar phiTheta x
TrainingTrackerPlotter  x
plantuml bandit x

short corridor x
EnvironmentSC  x
TestEnvironmentSC  x
AgentSC x
korrekt stateObserved  x
TestAgentSC x
clean up  x
tracker.addActionProbabilities x
RunnerShortCorridor  x
shortCorridor.md  x

sink the ship  x
EnvironmentShip x
TestEnvironmentShip  x

TrainerAbstractSC, record TrainerSettings med nofEpisodes etc  x

short corridor baseline TrainerWithBaselineSC  x
shortCorridor.md om baseline  x
RunnerTrainerWithBaselineSC  x
short corridor one step actor critic  TrainerWithActorCriticSC  x
Experience.copyWithReturn()  x
ny klass TabularValueFunction, för tex TrainerActorCriticSC  x
uppdatera plantuml  x


AgentShip  x
TestAgentShip  x
calcGradLogVector  createGradLogAllStates x
givenState0_whenGradLogForActionMeanS1_thenCorrect x
TrainerShip x
RunnerTrainerActorCriticShip  x
korrekt gradlog x
sinkShip.md  x
undivka div noll gradMean x
clip gragLog vektor x
sqr2 etc till MyFunctions x
tracker.addActionProbabilities  -> addMeasures etc  x
getExperiences: while(!sr.isTerminal() && si < parameters.nofStepsMax()) i andra miljör  x
TrainerAbstract  x
NormDistributionSampler x
ExperienceContAction Experience, båda!! går göra snyggare?  x
kommentera klasser  x
clean up


förstå https://www.janisklaise.com/post/rl-policy-gradients/
koda ovan
EnvironmentPole x
kolla av och snygga upp EnvironmentPole  x
TestEnvironmentPole  x
AgentPole x
TestAgentPole  x
TrainerVanillaPole  x
TestTrainerVanillaPole x
RunnerTrainersPole x
TrainerBaselinePole x
BaselinePole i runner  x
NStepReturnInfoPole x
TestNStepReturnInfoPole  x
TestTrainerActorCriticPole x
pseudocode n-step AC  x
få till AC utan minne stort n X
enkla dl4j exempel
få till nätverk som tar in pole states
testträna ovan
införliva i n-step AC x
FitSum2  x
Normalizer x
FitSum2 normalzed x
clener x
NeuralValueFunctionPole  x
normalizer i ovan  x
TestNeuralValueFunctionPole x
TestNormalizer  x
kunnna anropa train flera ggr utan create etc  x
normarizer out NeuralSum x
oven men i NeuralPole  x
slumpstate test i TestNeuralValueFunctionPole x
NeuralValueFunctionPole 2 hidden x
valueFunction med avg of n-step
RunnerTrainersPole
TrainerActorCriticPole med Neural mem
beta -> learningRateCritic, learningRate -> learningRateActor

correct AC

startState som TrainerParameters
ParametersPole clean with builder consttuccotr

ovan med anpassad loss

tex short corridor med neuronnät


bubblare:
gradLog with finite diff