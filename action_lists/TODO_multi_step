
TestForkEnvironment x
AgentTabular  x
TestAgentTabular  x
TestNstepTD x
NStepTDHelper x
låta PROB_RANDOM minska med episod x
snygga upp TestNstepTD  x
ScalerLogarithmic   x
klass NStepEpisodeRunner  x
TestNStepEpisodeRunner  x
påvisa större n ger snabbare konvergens  x

input vec length = antal states  x
AgentHelper  x
AgentNetwork x
TestAgentForkNeural  x
AgentForkNeural learn  x
NStepNeuralAgentTrainer - getMiniBatch  x
NStepNeuralAgentTrainer - setValuesInExperiencesInMiniBatch  x
NStepNeuralAgentTrainer - trainAgentFromExperiencesInMiniBatch x
TestNStepNeuralAgentTrainer x
Uppdatera nn varje steg  x
cvarför låser sig ibland  - behöver clip, learningRate viktigt x
ForkNeuralValueMemory konstruktor  x
studera några episoder så verkligen korrekt experience  x
ändra steps - studera epis x
value = 0 ibland  x
newDefault snyggare x
setValuesInExperiencesInMiniBatch - discount hänsyn  x
testa olika discount TestNStepNeuralAgentTrainer  x
test - innan terminal state skall discúnt ej påverka  x
givenStartingAtState7_whenTrainedWithMoreSteps_thenFasterLearning  x
clean up TestNStepNeuralAgentTrainer x
plantuml multi step  x
AgentAbstract  x
AgentForkTabular extends AgentAbstract  x
ta veck chooseRandomAction etc i AgentIterface  x
rita om planutml med AgentAbstract x
clean up
EnvironmentInterface - ta bort Set<Integer> stateSet()   - EnvironmentDiscreteStatesInterface blir för bökigt x
AgentInfo - lägg till getDiscountFactor   x
AgentInterface - ta bort getDiscountFactor  x
AgentAbstract - lägg till fält nofSteps  x
AgentInfo - kom åt nofSteps  x
Test för nofSteps  x
ny klass i AgentAbstract TemporalDifferenceTracker  x
AgentInfo - kom åt TemporalDifferenceTracker med olika filter tidsfönster  x
TestTemporalDifferenceTracker  x
plott ex trackTempDifferenceErrors x
trackTempDifferenceErrors i NStepNeuralAgentTrainer x
plotta ovan  x

generisc state x
whenActionIs0Or1InState14_thenState15AndTerminalAndRewardHell x
planutml med generisc state  x
NetworkMemoryInterface mer clean ISP  x

Annan miljö - tex Maze
MazeEnvironment x
TestMazeEnvironment  x
TestNStepTabularAgentTrainerMaze  x
function för start state  x
State = MazeVariables(x=1, y=5), value = 115.90638230139263  x
TestNStepNeuralAgentTrainerMaze  x
pusha  x
printMaze i TestHelper  x
printa G isf  x

skapa AgentTabularInterface med writeValue  x
writeValue skall ej behövas i agentAbstract  x
plantuml AgentTabularInterface  x

ny miljö slideInCharge x
TestChargeEnvironmentBTrapped x
TestChargeEnvironmentBRunning  x

AgentChargeGreedy  x
TestAgentChargeGreedy  x
ändra charge miljö till mer som P
- P charge started x
- gamla till trash x
- ChargeEnvironmentSettings x
- ChargeEnvironmentLambdas - skall ta emot ChargeEnvironmentSettings  x
- införliva ChargeEnvironmentSettings  x
- införliva ChargeEnvironmentLambdas x
- modda PositionTransitionRules x
- TestPositionTransitionRules  x
- modda SiteStateRules x
- TestSiteStateRules  x
- ChargeEnvironment: Pair<Integer, Integer> ->  Positions  x
- ChargeEnvironment: Pair<Double, Double> -> SoCLevels x
- TestCharge ..  x
- TestAgentChargeGreedy x
- fler tester TestAgentChargeGreedy - tex med obstacle x
- färstå "0,10,0.9,0.9, false,1,20" x
- clearner chooseBestAction x
- studera/clean up AgentChargeGreedy x
- clean up ChargeEnvironment , tex and or i lampda expr, x
- clean up trainers  x
- snyggare print state - soc många decimaler   x

StepReturn isNewStateFail andra miljör  x

AgentChargeGreedyRuleForChargeDecisionPoint  x
TestAgentChargeGreedyRuleForChargeDecisionPoint x
RunnerAgentChargeGreedyRuleForChargeDecisionPoint x
andel still que i ovan  x
TestAgentChargeGreedyRuleForChargeDecisionPoint x
pos A =7, pos B = 8 -> A stannar - bara que vis 20 straffades  x

AgentChargeNeural
- AgentChargeNeural init x
- AgentChargeNeuralSettings x
- NeuralValueMemoryCharge x
- InputVectorSetterChargeInterface x
- PositionMapper  x
- TestInputSetterSoCAtOccupiedZeroOther  x
- TestAgentNeuralChargeMockedData
- TestAgentNeuralChargeMockedData - givenRuleBasedValue_whenTrain_thenCorrect  x
- plot network error vs iteration  x
- ScalerLinear -> Normalizer  x
- NormalizerInterface  x
- NormalizerInterface -> NormalizerMinMax NormalizerMeanStd  x
- TestNormalizer  x
- apply Normalizer InputSetterSoCAtOccupiedZeroOther  x
- tester funkar x
- apply Normalizer out  x
- constructor i ValueMemoryNetworkAbstract  x
- NetSettings - nof Layers  x
- TestAgentNeuralChargeMockedData clean up - x
- Plotta egentiga felet  x
- RunnerChargeNeuralMocked - med olika inställmningar  x
- hot encoding positions+socs  x
- RunnerChargeNeuralMocked cleaner x
- MockedReplayBufferCreatorCharge i TestAgent..  x
- Andra TransferFunctionType  x
. AgentMazeNeuralSettings gör snyggare -utan getWithDiscountAndLearningRate x
- få TestAgentNeuralChargeMockedData stabil x
- momentum x

RunnnerAgentChargeNeuralBTrapped - Testa ovan när B är trapped x
- flytta discountFactor från AgentAbstract till AgentSettins  x
- olikma momentum x
- discount factor x
- reset memory x
- bugg still 20 x
- kör episoder x
- ChargeEnv energi minskar även om står still x
- RunnerAgentChargeNeuralTrainerBTrapped funkar x
- mindre max tid tränning  x
- simulering efter träning med större max tid  x
- plotta v20-v11 för olika soc x
- PlotterMultiplePanelsRelation  x
- ovan för 20-100 soc  x
- zoom in TD error plot  x

- prova resetta innan  x
- ny klass AgentEvaluator  x
- plotta G vs episode  x
- agent.setState(state) - missat annat ställe?  x
- word dokumnetera  x

Overall cleaning  x
Mer i hjälp klas RunnerBTrapped x

TestAgentChargeNeuralBothFree  x
RunnerNormalizerMeanStd - testa olika bad*x  x
test alpha =3,5  x
kunna spara nätverk  x
memory classes plantuml   x
ChargeInitStateVariantsEvaluator x
record Scenario - scenario ta in namn  x
RunnerChargeScenariosEvaluator x
BUGG RunnerChargeScenariosEvaluator ger olika results  x
bug fixad - missade sortering i PositionMapper x
- visa tid runner  x
sum reweards log trainer x
variant BatPosSplit_AatPos40_BothModerateSoC  x
TD error log trainer x
scenario 1000 steg - jämföra med rule based x
stabil körning RunnerAgentChargeNeuralTrainerBothFree x

HyperParameterOptimizer
mer data till ChargeAgentParameters
remove item full buffer
prova target network

givenRuleBasedValue_whenTrain_thenCorrect fuckar
snygga upp plotters - tex inställningar i konstruktor
- MultiePanelScatterPlot
- MultiePanelScatterPlot

RunnerAgentChargeGreedyRuleForChargeDecisionPointObstacleSomeTimes med obstacle ibland

grafix för ovan

röriga konstruktors if AgentForkNeural

ide om två nn minnen - ett med större intervall med terminal fail fokus
för ovan testa ide grovt på mockad data på nät

- Ev sandbox example, 4 ingångar, ut litet om ngn av två första mindre än 0.5

ev target network
https://en.wikipedia.org/wiki/Encog
