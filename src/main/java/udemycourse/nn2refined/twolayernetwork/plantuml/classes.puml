@startuml
class ActivFunction {
+ float sigmoid(float x)
+ float dSigmoid(float x)
}

class Layer {
    float[] inVec;
    float[] outVec;
    float[] weights;
    float[] dWeights;

    + float[] calcOut(float[] inVec)
    + float[] train([] error,  learningRate,  momentum)
    + float[] calcErrorVecOutput([] outVec, [] calculatedOutput)
    + showProgress(...)
    + showNetworkResponse(...)
    - initializeWeights()
    - float[] calcNetSum(int idxOut)
    - int calcIndexWeight(int idxOut, int idxIn)
}

note bottom
<math>  dw_kj=-learningRate*dE/da_k*da_k/dn_k*dn_k/dw_kj </math>
<math>  =-learningRate*(-ta-a)*(derA(a)*(aj) </math>
<math>  =-learningRate*delta*aj </math>
layer k, input j
Intuition: "change weight if affects error and connected to input"
end note

class NeuralNetwork {
    Layer[] layers;

    + float[] calcOutput(float[] inVec)
    + train(float[] inVec, float[] outVec, float learningRate, float momentum)
    - float[] calcErrorVecOutput(float[] outVec, float[] calculatedOutput)
    - trainAllLayers(float learningRate, float momentum, float[] errorOut)

}

class DataSetter {
setup parameters, e.g. LEARNING_RATE;
float[][] inData;
float[][] outData;

+ defineSetup();
+ defineInData();
+ defineOutData();


}

class XORData { }
class IrisData { }
class CircleClassifierData { }
class NumberImagesData { }

NeuralNetwork "1" *-- "2" Layer
Layer --> ActivFunction

DataSetter <|-- XORData
DataSetter <|-- IrisData
DataSetter <|-- CircleClassifierData
DataSetter <|-- NumberImagesData

@enduml

