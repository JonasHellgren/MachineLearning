


undvika calcOutX calcOutY, sätt flip som klass parameter  x
marginal i Frame  X
skapa separat package: Java based open GYM  x

Environment som abstract isf interface x
getParameters();  //polymorphism: can return any sub class of EnvironmentParametersAbstract  stämmer?? behövs getParameters? onödig  X
Agent interface döps om till Learnable x
Bas klass för agent tabular x
Bas klass för agent nn  x
skapa method för "INDArray inputNetwork = state.getStateVariablesAsNetworkInput(envParams)"  x
Warning: Initializing ND4J with Generic x86 binary on a CPU with AVX/AVX2 support
testa med regel baserad action för MountainCar, tex 2 om pos>tbd och 0 om pos<tbd  X
startPosition verkar fel x
printa pos and speed i panel  x
förstå varför grafik ej visas ibland x
MountainCar agent
---------------
inte behöva träna nn varje steg  x
ibland vissa policy för episode med start i tbd  x
träna olika värden olika states x
learnAtDifferentInputsZeroGamma  FUCKAR  !!
skap PanelMountainCarPlot  x
plotta policy x
antal steg isf antal episoder avgör networkTarget uppdatering etc x
prova SixRooms  x
learnAtSameInputStandardRewardNonZeroGamma verkar krångla   x
kolla av nof steps, nollställa vid rätt tillfälla. totalNofSteps i state, nofFits i AgentNetwork, nofSteps i "specific" State.
snygga upp kod, tex några metoder från test klass in i andra klasser,   x
stepReturn.reward=-1 för learnAtSameInputStandardRewardNonZeroGamma
undvika kalla createContinuousVariable flera ggr x
skapa seperata test för funk approx  resp inlärning  x
alternativ reward
lära sig Q för regelabserad, väl lika mellan actions x
nofFits:2376, totalNofSteps:1227936 stämmer inte
nyanlända experience, prioritet?  x
normalisiering   x
större replay buffer
ändra range
MIN_START_VELOCITY och MIN_START_POS ändrat
minska q learning rate
förträna så att allla Qsa är -100
testPlicy printa mer än succes ratio, tex bellman error, antal steg
annan nn arkitekur
pusha till repo


minskande learning rate

spara policy/nn

ett lager mindre

test där stor exp replay buffer skapas som agent trånas från
bellmanError verkar för litet
detaljstudera episod
printa exempel nn out  x
mer info för varje episode, tex score, max pos, nn ut vid tbd x
fixa bellmanErrorList for 6Rooms
snabba upp SixRooms




när tid:
binary string variable i State   https://stackoverflow.com/questions/7602665/store-an-array-in-hashmap/7602742
prova relu som activ function för six rooms
GPU vs CPU för riktigt stor nn/batch
normalize regression examples
udemu ai4 bandit example
Test saving fail states-actions